{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AutoEncoderMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2LU-6ViDEgC",
        "outputId": "7092a63d-7fdc-47cd-eafb-3f4d16522b74"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMNRB32NLzVF",
        "outputId": "8cf0c331-75d7-4b84-8a44-486d2cad3f5c"
      },
      "source": [
        "!pip install idx2numpy acoustics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/6b/80628f6cc2f44d80b27f1ef7b57b257ed4c73766113b77d13ad110c091b4/idx2numpy-1.2.3.tar.gz\n",
            "Collecting acoustics\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/8f/0738c42706c8cd10b077e3116d1d1b41e61b1daf2596cba847368274c862/acoustics-0.2.4.post0.tar.gz (851kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from idx2numpy) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from acoustics) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from acoustics) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.15 in /usr/local/lib/python3.7/dist-packages (from acoustics) (1.1.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from acoustics) (0.8.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->acoustics) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->acoustics) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->acoustics) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->acoustics) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.15->acoustics) (2018.9)\n",
            "Building wheels for collected packages: idx2numpy, acoustics\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-cp37-none-any.whl size=7907 sha256=9091bab1aa6fa32ddc3bdd557466f06b0f04a46d6159e6c955f0795b9e21c964\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c1/da/284ce80a748fab898b8d1fa95468a386e7cf3b81da18511f9d\n",
            "  Building wheel for acoustics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acoustics: filename=acoustics-0.2.4.post0-cp37-none-any.whl size=68741 sha256=ff560c7b1710addc4ef37deae9c8af2159cfd724cba38936f0804902f68cc407\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/15/f8/dcf1503edc7c990e0b0d309bf8ca5efa14f1daed5eef9ba2f9\n",
            "Successfully built idx2numpy acoustics\n",
            "Installing collected packages: idx2numpy, acoustics\n",
            "Successfully installed acoustics-0.2.4.post0 idx2numpy-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_AiGYXWJT7E"
      },
      "source": [
        "import numpy as np\n",
        "import idx2numpy\n",
        "import pandas as pd \n",
        "import cv2\n",
        "import gzip\n",
        "import os\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import acoustics\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2snE9lCSPTF"
      },
      "source": [
        "# Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lddkQBEkDcef"
      },
      "source": [
        "directorypathtrain = \"/content/drive/MyDrive/MNIST/Clean/train-images.idx3-ubyte\"  #pathtotrainingimages\n",
        "directorypathtest = \"/content/drive/MyDrive/MNIST/Clean/t10k-images.idx3-ubyte\" #pathtotestingimages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J85G9vDsLuaZ"
      },
      "source": [
        "def get_images(directorypath):\n",
        "    imagearray = idx2numpy.convert_from_file(directorypath)\n",
        "    return imagearray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFFc_Ds6JJMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95056ed2-64f6-495e-b508-753446376865"
      },
      "source": [
        "trainimages = get_images(directorypathtrain)\n",
        "print(trainimages.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h9ebD_i1X51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b3e778-faf5-4d14-9ff3-9223f7071d9e"
      },
      "source": [
        "testimages = get_images(directorypathtest)\n",
        "print(testimages.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qe-T_T9spb2"
      },
      "source": [
        "#Adding Noise Manually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHYSSQTZstqU"
      },
      "source": [
        "###Motion Blur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwBRPU10ssAF"
      },
      "source": [
        "#motion blur\n",
        "def motion_blur_kernel(image, degree=5, angle=15):\n",
        "    # image = np.array(image)\n",
        "\n",
        "    # This generates a matrix of motion blur kernels at any angle. The greater the degree, the higher the blur.\n",
        "    M = cv2.getRotationMatrix2D((degree / 2, degree / 2), angle, 1)\n",
        "    motion_blur_kernel = np.diag(np.ones(degree))\n",
        "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
        "\n",
        "    motion_blur_kernel = motion_blur_kernel / degree\n",
        "    blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
        "\n",
        "    # convert to uint8\n",
        "    cv2.normalize(blurred, blurred, 0, 255, cv2.NORM_MINMAX)\n",
        "    blurred = np.array(blurred, dtype=np.uint8)\n",
        "    \n",
        "    return blurred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9LhKpUwsvqn"
      },
      "source": [
        "###AWGN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ83vta_ByYi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtAowC9ts0e8"
      },
      "source": [
        "def add_awgn_noise(image, snr=9.5):\n",
        "    # Generate the noise as you did\n",
        "    noise = acoustics.generator.white(image.size).reshape(*image.shape)\n",
        "    # For the record I think np.random.random does exactly the same thing\n",
        "\n",
        "    # work out the current SNR\n",
        "    current_snr = np.mean(image) / np.std(noise)\n",
        "\n",
        "    # scale the noise by the snr ratios (smaller noise <=> larger snr)\n",
        "    noise *= (current_snr / snr)\n",
        "\n",
        "    # return the new signal with noise\n",
        "    return image + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhrdzz79s0rS"
      },
      "source": [
        "###Reduced Contrast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQEQe6sdtRg8"
      },
      "source": [
        "def reduce_contrast(image, awgnsnr=12, factor=0.5):\n",
        "  image = image*factor\n",
        "  image = add_awgn_noise(image, 12)\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQSYyFu0zGBm"
      },
      "source": [
        "##Creating Separate Datasets for Each Type of Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhcdGgCoy8KM"
      },
      "source": [
        "def datasetformation(image_array, SNR=12, angle=15, degree=5, factor=0.5, training=True):\n",
        "  \n",
        "  iter = 0\n",
        "  if training:\n",
        "    iter = 60000\n",
        "  else:\n",
        "    iter = 10000\n",
        "\n",
        "  awgn_data = np.zeros((iter,28,28))\n",
        "  motion_blur_data = np.zeros((iter,28,28))\n",
        "  reduced_contrast_data = np.zeros((iter,28,28))\n",
        "\n",
        "  for num in tqdm(range(iter)):\n",
        "    image = image_array[num]\n",
        "    awgn_image = add_awgn_noise(image, snr=9.5)\n",
        "    motion_blur_image = motion_blur_kernel(image, degree=5, angle=15)\n",
        "    reduced_contrast_image = reduce_contrast(image, awgnsnr=12, factor=0.5)\n",
        "    awgn_data[num] = awgn_image\n",
        "    motion_blur_data[num] = motion_blur_image\n",
        "    reduced_contrast_data[num] = reduced_contrast_image\n",
        "  \n",
        "  if training:\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/awgn_train.npy\", awgn_data)\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/motion_blur_train.npy\", motion_blur_data)\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_train.npy\", reduced_contrast_data)\n",
        "\n",
        "  else:\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/awgn_test.npy\", awgn_data)\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/motion_blur_test.npy\", motion_blur_data)\n",
        "    np.save(\"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_test.npy\", reduced_contrast_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeljoGpW4mvg"
      },
      "source": [
        "datasetformation(trainimages, training=True)\n",
        "datasetformation(testimages, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "184QJlyM7965"
      },
      "source": [
        "#form the vectorized inputs and save\n",
        "awgnpath = \"/content/drive/MyDrive/MNIST/Clean/awgn_test.npy\"\n",
        "motionblurpath = \"/content/drive/MyDrive/MNIST/Clean/motion_blur_test.npy\"\n",
        "reducedcontrastpath = \"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_test.npy\"\n",
        "groundtruthpath = \"/content/drive/MyDrive/MNIST/Clean/t10k-images.idx3-ubyte\"\n",
        "groundtruthimages = idx2numpy.convert_from_file(groundtruthpath)\n",
        "awgnimages = np.load(awgnpath)\n",
        "motionblurimages = np.load(motionblurpath)\n",
        "reducedcontrastimages = np.load(reducedcontrastpath)\n",
        "\n",
        "gdvector = np.zeros((10000,784))\n",
        "awgnvector = np.zeros((10000,784))\n",
        "mbvector = np.zeros((10000,784))\n",
        "rcvector = np.zeros((10000,784))\n",
        "\n",
        "for i in range(10000):\n",
        "  awgnsingle = np.reshape(awgnimages[i, : ,:], (784))\n",
        "  awgnvector[i] = awgnsingle\n",
        "  mbsingle = np.reshape(motionblurimages[i, : ,:], (784))\n",
        "  mbvector[i] = mbsingle\n",
        "  rcsingle = np.reshape(reducedcontrastimages[i, : ,:], (784))\n",
        "  rcvector[i] = rcsingle\n",
        "  gdsingle = np.reshape(groundtruthimages[i, : ,:], (784))\n",
        "  gdvector[i] = gdsingle\n",
        "\n",
        "  assert gdvector.shape == (10000, 784)\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/MNIST/Clean/awgn_test_vectorized.npy\", awgnvector)\n",
        "np.save(\"/content/drive/MyDrive/MNIST/Clean/motion_blur_test_vectorized.npy\", mbvector)\n",
        "np.save(\"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_test_vectorized.npy\", rcvector)\n",
        "idx2numpy.convert_to_file(\"/content/drive/MyDrive/MNIST/Clean/t10k-images_vectorized.idx3-ubyte\", gdvector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du95Diz7PLMP"
      },
      "source": [
        "# Noisy Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JNqAEgUN_ww"
      },
      "source": [
        "# awgn_path = \"/content/drive/MyDrive/MNIST/Noise/AWGN/mnist-with-awgn.mat\"\n",
        "# motionblur_path = \"/content/drive/MyDrive/MNIST/Noise/MotionBlur/mnist-with-motion-blur.mat\"\n",
        "# reduced_path = \"/content/drive/MyDrive/MNIST/Noise/ReducedContrast/mnist-with-reduced-contrast-and-awgn.mat\"\n",
        "# awgnmat = scipy.io.loadmat('/content/drive/MyDrive/MNIST/Noise/AWGN/mnist-with-awgn.mat')\n",
        "# trainimage = (awgnmat['train_x'][1])\n",
        "# print(trainimage.shape)\n",
        "# trainimage = np.reshape(trainimage, (28, 28))\n",
        "# print(trainimage.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMw9leD82ih"
      },
      "source": [
        "#Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU_N2cMd80rL"
      },
      "source": [
        "class NoisyMNISTDataset(Dataset):\n",
        "  def __init__(self, noisetype, noisedir, rootdir, vectorized = False):\n",
        "    self.noisetype = noisetype\n",
        "    self.noisedir = noisedir\n",
        "    self.groundtruthpath = rootdir\n",
        "    self.vectorized = vectorized\n",
        "  \n",
        "  def __len__(self):\n",
        "    return idx2numpy.convert_from_file(self.groundtruthpath).shape[0]   #examples in training set\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    \n",
        "    groundtruthimage = idx2numpy.convert_from_file(self.groundtruthpath)[idx]\n",
        "    noiseinputimage = np.load(self.noisedir)[idx]\n",
        "\n",
        "    if self.vectorized:\n",
        "      groundtruthvector = np.reshape(groundtruthimage, (groundtruthimage.shape[0]*groundtruthimage.shape[1],))\n",
        "      noiseinputvector = np.reshape(noiseinputimage, (noiseinputimage.shape[0]*noiseinputimage.shape[1],))\n",
        "\n",
        "      del groundtruthimage, noiseinputimage\n",
        "\n",
        "      assert groundtruthvector.shape == (784,)\n",
        "      assert noiseinputvector.shape == (784,)\n",
        "      \n",
        "      return (noiseinputvector, groundtruthvector)\n",
        "\n",
        "    else:\n",
        "      assert groundtruthimage.shape == (28,28)\n",
        "      assert noiseinputimage.shape == (28,28)\n",
        "\n",
        "      return (noiseinputarray, groundtrutharray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BXIx8Zp88D3"
      },
      "source": [
        "#Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3_3Xo6zb-N8"
      },
      "source": [
        "###Training Dataloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JirlJp1JeEjI"
      },
      "source": [
        "####Vectorized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4t_HYsabat5"
      },
      "source": [
        "awgntrain = NoisyMNISTDataset('awgn', noisedir=\"/content/drive/MyDrive/MNIST/Clean/awgn_train.npy\", \n",
        "                              rootdir=\"/content/drive/MyDrive/MNIST/Clean/train-images.idx3-ubyte\", vectorized=True)\n",
        "\n",
        "motionblurtrain = NoisyMNISTDataset('motionblur', noisedir=\"/content/drive/MyDrive/MNIST/Clean/motion_blur_train.npy\", \n",
        "                              rootdir=\"/content/drive/MyDrive/MNIST/Clean/train-images.idx3-ubyte\", vectorized=True)\n",
        "\n",
        "reducedcontrasttrain = NoisyMNISTDataset('reducedcontrast', noisedir=\"/content/drive/MyDrive/MNIST/Clean/reduced_contast_train.npy\", \n",
        "                              rootdir=\"/content/drive/MyDrive/MNIST/Clean/train-images.idx3-ubyte\", vectorized=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to_zQC7nedB_"
      },
      "source": [
        "# params = {\"batch_size\":batch_size, \n",
        "#           \"shuffle\":True, \n",
        "#           \"num_workers\":0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6ZUkp7ehdL"
      },
      "source": [
        "# awgntrainloader = DataLoader(awgntrain, **params)\n",
        "# # motionblurtrainloader = DataLoader(motionblurtrain, **params)\n",
        "# # reducedcontrasttrainloader = DataLoader(reducedcontrasttrain, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BPP6uqxTYE_"
      },
      "source": [
        "# Vectorized Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO7_h3-BowAD"
      },
      "source": [
        "class VectorizedDenoisingAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VectorizedDenoisingAutoencoder, self).__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.enc1 = nn.Linear(in_features=784, out_features=676)\n",
        "        self.enc2 = nn.Linear(in_features=676, out_features=576) \n",
        "        self.enc3 = nn.Linear(in_features=576, out_features=512)\n",
        "        self.enc4 = nn.Linear(in_features=512, out_features=400)\n",
        "        self.enc5 = nn.Linear(in_features=400, out_features=256)\n",
        "        self.enc6 = nn.Linear(in_features=256, out_features=128)\n",
        "        self.enc7 = nn.Linear(in_features=128, out_features=64)\n",
        "        self.enc8 = nn.Linear(in_features=64, out_features=32)\n",
        "\n",
        "        #Decoder \n",
        "        self.dec1 = nn.Linear(in_features=32, out_features=64)\n",
        "        self.dec2 = nn.Linear(in_features=64, out_features=128)\n",
        "        self.dec3 = nn.Linear(in_features=128, out_features=256)\n",
        "        self.dec4 = nn.Linear(in_features=256, out_features=400)\n",
        "        self.dec5 = nn.Linear(in_features=400, out_features=512)\n",
        "        self.dec6 = nn.Linear(in_features=512, out_features=576)\n",
        "        self.dec7 = nn.Linear(in_features=576, out_features=676)\n",
        "        self.dec8 = nn.Linear(in_features=676, out_features=784) # Output image (28*28 = 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = F.relu(self.enc2(x))\n",
        "        x = F.relu(self.enc3(x))\n",
        "        x = F.relu(self.enc4(x))\n",
        "        x = F.relu(self.enc5(x))\n",
        "        x = F.relu(self.enc6(x))\n",
        "        x = F.relu(self.enc7(x))\n",
        "        x = F.relu(self.enc8(x))\n",
        "\n",
        "        x = F.relu(self.dec1(x))\n",
        "        x = F.relu(self.dec2(x))\n",
        "        x = F.relu(self.dec3(x))\n",
        "        x = F.relu(self.dec4(x))\n",
        "        x = F.relu(self.dec5(x))\n",
        "        x = F.relu(self.dec6(x))\n",
        "        x = F.relu(self.dec7(x))\n",
        "        x = F.relu(self.dec8(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXrs9ALvABTe"
      },
      "source": [
        "##Vectorized Autoencoder - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRzNOPYrAAT_"
      },
      "source": [
        "class VectorizedDenoisingAutoencoderModified(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VectorizedDenoisingAutoencoderModified, self).__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.enc1 = nn.Linear(in_features=784, out_features=512)\n",
        "        self.enc2 = nn.Linear(in_features=512, out_features=256) \n",
        "        #Decoder \n",
        "        self.dec1 = nn.Linear(in_features=256, out_features=512)\n",
        "        self.dec2 = nn.Linear(in_features=512, out_features=784)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = F.relu(self.enc2(x))\n",
        "\n",
        "        x = F.relu(self.dec1(x))\n",
        "        x = F.relu(self.dec2(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAU4jJBVPcTE"
      },
      "source": [
        "#Vectorized Autoencoder - 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHRVDwgnPiym"
      },
      "source": [
        "class VectorizedDenoisingAutoencoderThree(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VectorizedDenoisingAutoencoderThree, self).__init__()\n",
        "\n",
        "        #Encoder\n",
        "        self.enc1 = nn.Linear(in_features=784, out_features=512)\n",
        "        # self.enc2 = nn.Linear(in_features=512, out_features=256)\n",
        "        # self.enc3 = nn.Linear(in_features=256, out_features=128) \n",
        "\n",
        "        #Decoder \n",
        "        # self.dec1 = nn.Linear(in_features=128, out_features=256)\n",
        "        # self.dec2 = nn.Linear(in_features=256, out_features=512)\n",
        "        self.dec3 = nn.Linear(in_features=512, out_features=784)\n",
        "        # self.dec4 = nn.Linear(in_features=256, out_features=400)\n",
        "        # self.dec5 = nn.Linear(in_features=400, out_features=512)\n",
        "        # self.dec6 = nn.Linear(in_features=512, out_features=576)\n",
        "        # self.dec7 = nn.Linear(in_features=576, out_features=676)\n",
        "        # self.dec8 = nn.Linear(in_features=676, out_features=784) # Output image (28*28 = 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.enc1(x))\n",
        "        # x = F.relu(self.enc2(x))\n",
        "        # x = F.relu(self.enc3(x))\n",
        "\n",
        "        # x = F.relu(self.dec1(x))\n",
        "        # x = F.relu(self.dec2(x))\n",
        "        x = F.relu(self.dec3(x))\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lE2Gnr7gmE8"
      },
      "source": [
        "####AWGN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzi47eTme9BH"
      },
      "source": [
        "# awgnmodel = VectorizedDenoisingAutoencoderModified()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VceMRfbGgxSx"
      },
      "source": [
        "####MotionBlur Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "351ZlO_dgts_"
      },
      "source": [
        "# motionblurmodel = VectorizedDenoisingAutoencoderModified()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vssFoikFg6F4"
      },
      "source": [
        "####ReducedContrastModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6cfaeQMgp5S"
      },
      "source": [
        "reducedcontrastmodel = VectorizedDenoisingAutoencoderModified()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2RtrrSQhCLb"
      },
      "source": [
        "####Criterion, Optimizer and Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A4jbKm5guf9"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(reducedcontrastmodel.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "num_epochs = 100\n",
        "dropout = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVeFjJu50r2"
      },
      "source": [
        "awgnpath = \"/content/drive/MyDrive/MNIST/Clean/awgn_train_vectorized.npy\"\n",
        "motionblurpath = \"/content/drive/MyDrive/MNIST/Clean/motion_blur_train_vectorized.npy\"\n",
        "reducedcontrastpath = \"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_train_vectorized.npy\"\n",
        "groundtruthpath = \"/content/drive/MyDrive/MNIST/Clean/train-images_vectorized.idx3-ubyte\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D3D260pOUc6"
      },
      "source": [
        "# awgnpathval = \"/content/drive/MyDrive/MNIST/Clean/awgn_test_vectorized.npy\"\n",
        "# mbpathval = \"/content/drive/MyDrive/MNIST/Clean/motion_blur_test_vectorized.npy\"\n",
        "# rcpathval = \"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_test_vectorized.npy\"\n",
        "# gtpathval = \"/content/drive/MyDrive/MNIST/Clean/t10k-images_vectorized.idx3-ubyte\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHBTDCae6PiK"
      },
      "source": [
        "noiseinputpath = reducedcontrastpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wnOnYGV_4zF"
      },
      "source": [
        "groundtruthvectors = idx2numpy.convert_from_file(groundtruthpath)\n",
        "noiseinputvectors = np.load(noiseinputpath)\n",
        "\n",
        "# groundtruthvectorsval = torch.from_numpy(idx2numpy.convert_from_file(gtpathval).astype(np.float32))\n",
        "# noiseinputvectorsval = torch.from_numpy(np.load(noiseinputpathval).astype(np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRPB0UL0RBYb"
      },
      "source": [
        "# print(noiseinputvectorsval[10].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Po_dgoebnj"
      },
      "source": [
        "batch_size = 64 #main control of batch size is here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqHgqcDrx90"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SrU_ZoB3AHHT",
        "outputId": "98392fb2-ea0a-46a4-aea7-90192e570ef2"
      },
      "source": [
        "#training loop\n",
        "reducedcontrastmodel.train()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    cumulative_loss = 0.0\n",
        "    # epoch_loss = 0.0    \n",
        "    batchstart = 0\n",
        "    batchend = batchstart + batch_size\n",
        "    numbatches = 0\n",
        "    for b in range(int(60000/batch_size)+1):              #60000/64 = 938\n",
        "        groundtruth = torch.from_numpy(groundtruthvectors[batchstart:batchend, :].astype(np.float32))   #(32,784)\n",
        "        inputs = torch.from_numpy(noiseinputvectors[batchstart:batchend, :].astype(np.float32))\n",
        "\n",
        "        model_output = reducedcontrastmodel(inputs)\n",
        "        loss = criterion(model_output, groundtruth)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cumulative_loss += loss.item()\n",
        "        if numbatches%300 == 0 and numbatches!=0:     \n",
        "            print (numbatches, end=' ')\n",
        "            print('Loss: ' , cumulative_loss)\n",
        "            print('-----------------------------------')\n",
        "            with open('/content/drive/MyDrive/MNIST/Models/reducedcontrastvectorizedmodifiedadam', 'at') as file :       \n",
        "                now = datetime.datetime.now()\n",
        "                current_time = now.strftime(\"%H:%M:%S\")\n",
        "                file.write(\"Epoch: {}, Batch: {}, Loss: {}, Time: {}\\n\".format(epoch, loss.item(), cumulative_loss, current_time))    \n",
        "        numbatches += 1\n",
        "        batchstart = batchend\n",
        "        batchend = batchstart + batch_size\n",
        "        # gc.collect()\n",
        "\n",
        "    print(\"Epoch Loss: \", cumulative_loss/60000)\n",
        "\n",
        "    # val_output = awgnmodel(noiseinputvectorsval[10].unsqueeze(0))\n",
        "    # val_output = val_output.detach().numpy()\n",
        "\n",
        "    # my_dpi = 40\n",
        "    # fig = plt.figure(figsize=(28, 28), dpi=my_dpi)\n",
        "\n",
        "    # ax1 = fig.add_subplot(1, 2, 1)\n",
        "    # ax1.imshow(np.reshape(noiseinputvectorsval[10], (28,28)), cmap='gray')\n",
        "\n",
        "    # ax2 = fig.add_subplot(1, 2, 2)\n",
        "    # ax2.imshow(np.reshape(val_output, (28,28)), cmap='gray')\n",
        "\n",
        "    if epoch%10 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': reducedcontrastmodel.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': 100\n",
        "            }, '/content/drive/MyDrive/MNIST/Models/reducedcontrastvectorizedmodifiedadam.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n",
            "Epoch Loss:  113.07944658203125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  1%|          | 1/100 [00:15<24:56, 15.12s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 2/100 [00:28<24:04, 14.74s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss:  113.07944658203125\n",
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 3/100 [00:42<23:24, 14.48s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss:  113.07944658203125\n",
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 4/100 [00:56<22:47, 14.24s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss:  113.07944658203125\n",
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 5/100 [01:10<22:18, 14.09s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss:  113.07944658203125\n",
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n",
            "600 Loss:  4372692.1005859375\n",
            "-----------------------------------\n",
            "900 Loss:  6520376.0830078125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  6%|▌         | 6/100 [01:24<21:54, 13.98s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Loss:  113.07944658203125\n",
            "300 Loss:  2186722.0258789062\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-876f32a3eee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducedcontrastmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcumulative_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOBv7TU3jaTR"
      },
      "source": [
        "savepath = \"/content/drive/MyDrive/MNIST/Models/awgnmodelval\" + str(10) + \".jpg\"\n",
        "\n",
        "fig.savefig(savepath, dpi=40, bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtyOaD4FKcWP"
      },
      "source": [
        "##Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGX--Wa5Kh23"
      },
      "source": [
        "###Vectorized Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "h2Nhtf_BK3uh",
        "outputId": "755cd282-f4ae-4f79-861d-7df7b59b189c"
      },
      "source": [
        "awgnpath = \"/content/drive/MyDrive/MNIST/Clean/awgn_test_vectorized.npy\"\n",
        "mbpath = \"/content/drive/MyDrive/MNIST/Clean/motion_blur_test_vectorized.npy\"\n",
        "rcpath = \"/content/drive/MyDrive/MNIST/Clean/reduced_contrast_test_vectorized.npy\"\n",
        "gtpath = \"/content/drive/MyDrive/MNIST/Clean/t10k-images_vectorized.idx3-ubyte\"\n",
        "\n",
        "awgnmodelpath = \"/content/drive/MyDrive/MNIST/Models/awgnvectorizedmodified.pt\"\n",
        "mbmodelpath = \"/content/drive/MyDrive/MNIST/Models/motionblurvectorizedmodified.pt\"\n",
        "rcmodelpath = \"/content/drive/MyDrive/MNIST/Models/reducedcontrastvectorizedmodified.pt\"\n",
        "\n",
        "\n",
        "awgntest = torch.from_numpy(np.load(awgnpath).astype(np.float32))\n",
        "mbtest = torch.from_numpy(np.load(mbpath).astype(np.float32))\n",
        "rctest = torch.from_numpy(np.load(rcpath).astype(np.float32))\n",
        "gt = torch.from_numpy(idx2numpy.convert_from_file(gtpath).astype(np.float32))\n",
        "\n",
        "awgnmodel = VectorizedDenoisingAutoencoderModified()\n",
        "# optimizer = torch.optim.Adam(awgnmodel.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optimizer = torch.optim.Adam(awgnmodel.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "# optimizer = torch.optim.Adam(awgnmodel.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "checkpoint = torch.load(awgnmodelpath)\n",
        "awgnmodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "awgnmodel.eval()\n",
        "\n",
        "mbmodel = VectorizedDenoisingAutoencoderModified()\n",
        "checkpoint = torch.load(mbmodelpath)\n",
        "mbmodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "mbmodel.eval()\n",
        "\n",
        "rcmodel = VectorizedDenoisingAutoencoderModified()\n",
        "checkpoint = torch.load(rcmodelpath)\n",
        "rcmodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "rcmodel.eval()\n",
        "\n",
        "awgnoutput = awgnmodel(awgntest)\n",
        "mboutput = mbmodel(mbtest)\n",
        "rcoutput = rcmodel(rctest)\n",
        "\n",
        "awgncriterion = nn.MSELoss()\n",
        "mbcriterion = nn.MSELoss()\n",
        "rccriterion = nn.MSELoss()\n",
        "\n",
        "awgnloss = awgncriterion(awgnoutput, gt)\n",
        "mbloss = mbcriterion(mboutput, gt)\n",
        "rcloss = rccriterion(rcoutput, gt)\n",
        "\n",
        "awgnoutput = awgnoutput.detach().numpy()\n",
        "mboutput = mboutput.detach().numpy()\n",
        "rcoutput = rcoutput.detach().numpy()\n",
        "\n",
        "print(\"AWGN Testing Loss: \", awgnloss.item()/64)\n",
        "print(\"Total Motion Blur Testing Loss: \", mbloss.item()/64)\n",
        "print(\"Total Reduced Contrast Testing Loss: \", rcloss.item()/64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a968211eec8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mawgntest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mawgnpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmbtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmbpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mrctest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcMT37L9WJ5W"
      },
      "source": [
        "#Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "4kJ_MmX4UHQk",
        "outputId": "f5b5987c-f10b-4427-8d7a-6a9ad7af9342"
      },
      "source": [
        "def plots(idx, awgntest, mbtest, rctest, groundtruth, awgnpredicted, mbpredicted, rcpredicted):\n",
        "  my_dpi = 40\n",
        "  fig = plt.figure(figsize=(28, 28), dpi=my_dpi)\n",
        "\n",
        "  ax1 = fig.add_subplot(3, 3, 1)\n",
        "  ax1.set_title(\"AWGN Image\", fontsize = 30)\n",
        "  ax1.set_xticks([])\n",
        "  ax1.set_yticks([])\n",
        "  ax1.imshow(np.reshape(awgntest[idx], (28,28)), cmap='gray')\n",
        "\n",
        "  ax2 = fig.add_subplot(3, 3, 2)\n",
        "  ax2.set_title(\"Motion Blur Image\",fontsize = 30)\n",
        "  ax2.set_xticks([])\n",
        "  ax2.set_yticks([])\n",
        "  ax2.imshow(np.reshape(mbtest[idx], (28,28)), cmap='gray')\n",
        "\n",
        "\n",
        "  ax3 = fig.add_subplot(3, 3, 3)\n",
        "  ax3.set_title(\"Reduced Contrast Image\",fontsize = 30)\n",
        "  ax3.set_xticks([])\n",
        "  ax3.set_yticks([])\n",
        "  ax3.imshow(np.reshape(rctest[idx], (28,28)), cmap='gray')\n",
        "\n",
        "  ax4 = fig.add_subplot(3, 3, 4)\n",
        "  ax4.set_title(\"Ground Truth Image\",fontsize = 30)\n",
        "  ax4.set_xticks([])\n",
        "  ax4.set_yticks([])\n",
        "  ax4.imshow(np.reshape(groundtruth[idx], (28,28)), cmap='gray')\n",
        "\n",
        "  ax5 = fig.add_subplot(3, 3, 5)\n",
        "  ax5.set_title(\"AWGN Model Prediction\",fontsize = 30)\n",
        "  ax5.set_xticks([])\n",
        "  ax5.set_yticks([])\n",
        "  ax5.imshow(np.reshape(awgnpredicted[idx], (28,28)), cmap='gray')\n",
        "\n",
        "  ax6 = fig.add_subplot(3, 3, 6)\n",
        "  ax6.set_title(\"Motion Blur Model Prediction\",fontsize = 30)\n",
        "  ax6.set_xticks([])\n",
        "  ax6.set_yticks([])\n",
        "  ax6.imshow(np.reshape(mbpredicted[idx], (28,28)), cmap='gray')\n",
        "\n",
        "  ax7 = fig.add_subplot(3, 3, 7)\n",
        "  ax7.set_title(\"Reduced Contrast Model Prediction\",fontsize = 30)\n",
        "  ax7.set_xticks([])\n",
        "  ax7.set_yticks([])\n",
        "  ax7.imshow(np.reshape(rcpredicted[idx], (28,28)), cmap='gray')\n",
        "\n",
        "\n",
        "\n",
        "  savepath = \"/content/drive/MyDrive/MNIST/Models/modifiedimagesplot\" + str(idx) + \".jpg\"\n",
        "\n",
        "  fig.savefig(savepath, dpi=40, bbox_inches='tight')\n",
        "\n",
        "idx = 101\n",
        "plots(idx, awgntest, mbtest, rctest, gt, awgnoutput, mboutput, rcoutput)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1120x1120 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPWA9TQHh9FC"
      },
      "source": [
        "#Image Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKtiIkxcbYhb"
      },
      "source": [
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "       \n",
        "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2, padding=2)  #28-16\n",
        "        # self.conv2 = nn.Conv2d(16, 32, 7)\n",
        "        self.conv2 = nn.Conv2d(16, 64, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(64, 256, 3, padding = 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "       \n",
        "        #Decoder\n",
        "        self.t_conv1 = nn.ConvTranspose2d(256, 64, 2, stride=2)   #4-8\n",
        "        self.t_conv2 = nn.ConvTranspose2d(64, 16, 2, stride=2)  #8-16\n",
        "        self.t_conv3 = nn.ConvTranspose2d(16, 1, 2, stride=2, padding=2) #16-28\n",
        "        # self.t_conv4 = nn.ConvTranspose2d(16, 1, 7)  \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        # print()\n",
        "        # x = F.relu(self.conv4(x))\n",
        "        # x = self.pool(x)\n",
        "        x = F.relu(self.t_conv1(x))\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.t_conv2(x))\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.t_conv3(x))\n",
        "        # print(x.shape)\n",
        "        # x = F.relu(self.t_conv4(x))\n",
        "              \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4XFOioQonfP",
        "outputId": "242a0ebf-c965-4efe-f188-311cc4e88bb3"
      },
      "source": [
        "conv = ConvAutoencoder()\n",
        "a = torch.rand(1,1,28,28)\n",
        "output = conv(a)\n",
        "print(\"output\", output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output torch.Size([1, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTUXKCH2m9MZ"
      },
      "source": [
        "# awgnmodel = ConvAutoencoder()\n",
        "motionblurmodel = ConvAutoencoder()\n",
        "# reducedcontrastmodel = ConvAutoencoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bDeTTV_mKHL"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(motionblurmodel.parameters(), lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "num_epochs = 20\n",
        "dropout = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81b5sz3Cweyh"
      },
      "source": [
        "awgnpath = \"/content/drive/MyDrive/MNIST/Clean/awgn_train.npy\"\n",
        "motionblurpath = \"/content/drive/MyDrive/MNIST/Clean/motion_blur_train.npy\"\n",
        "reducedcontrastpath = \"/content/drive/MyDrive/MNIST/Clean/reduced_contrast.npy\"\n",
        "groundtruthpath = \"/content/drive/MyDrive/MNIST/Clean/train-images.idx3-ubyte\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtV7vggmR5h"
      },
      "source": [
        "noiseinputpath = motionblurpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4KeM39WmZh3",
        "outputId": "79f5aaa8-00e2-43da-b301-73a8cf2c3dbf"
      },
      "source": [
        "groundtruthimages = idx2numpy.convert_from_file(groundtruthpath)\n",
        "noiseinputimages = np.load(noiseinputpath)\n",
        "print(groundtruthimages.shape, noiseinputimages.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SvzpV0pmhKK"
      },
      "source": [
        "batch_size = 64 #main control of batch size is here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo2BvtjLmhxz"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A-Hst8ZYmixw",
        "outputId": "6a2cef84-1d67-48e8-9e9a-0a747895fb70"
      },
      "source": [
        "#training loop\n",
        "motionblurmodel.train()\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    cumulative_loss = 0.0\n",
        "    epoch_loss = 0.0    \n",
        "    batchstart = 0\n",
        "    batchend = batchstart + batch_size\n",
        "    numbatches = 0\n",
        "    for b in range(int(60000/batch_size)+1):              #60000/64 = 938\n",
        "        groundtruth = torch.from_numpy(groundtruthimages[batchstart:batchend, :, :].astype(np.float32)).unsqueeze(1)  #(32,28, 28)\n",
        "        inputs = torch.from_numpy(noiseinputimages[batchstart:batchend, :, :].astype(np.float32)).unsqueeze(1)\n",
        "\n",
        "        model_output = motionblurmodel(inputs)\n",
        "        loss = criterion(model_output, groundtruth)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cumulative_loss += loss.item()\n",
        "        if numbatches%100 == 0 :     \n",
        "            print (numbatches, end=' ')\n",
        "            print('Loss: ' , cumulative_loss)\n",
        "            print('-----------------------------------')\n",
        "            with open('/content/drive/MyDrive/MNIST/Models/motionblurimages', 'at') as file :       \n",
        "                now = datetime.datetime.now()\n",
        "                current_time = now.strftime(\"%H:%M:%S\")\n",
        "                file.write(\"Epoch: {}, Batch: {}, Loss: {}, Time: {}\\n\".format(epoch, loss.item(), cumulative_loss, current_time))    \n",
        "        numbatches += 1\n",
        "        batchstart = batchend\n",
        "        batchend = batchstart + batch_size\n",
        "        # gc.collect()\n",
        "    \n",
        "    if epoch%1 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': motionblurmodel.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': 100\n",
        "            }, '/content/drive/MyDrive/MNIST/Models/motionblurimages.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  6965.65576171875\n",
            "-----------------------------------\n",
            "100 Loss:  741242.708984375\n",
            "-----------------------------------\n",
            "200 Loss:  1467348.2373046875\n",
            "-----------------------------------\n",
            "300 Loss:  2181094.501953125\n",
            "-----------------------------------\n",
            "400 Loss:  2916817.5805664062\n",
            "-----------------------------------\n",
            "500 Loss:  3602297.6547851562\n",
            "-----------------------------------\n",
            "600 Loss:  4317302.57421875\n",
            "-----------------------------------\n",
            "700 Loss:  5012884.3994140625\n",
            "-----------------------------------\n",
            "800 Loss:  5713210.867675781\n",
            "-----------------------------------\n",
            "900 Loss:  6405595.951660156\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 1/20 [01:38<31:05, 98.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  6784.0380859375\n",
            "-----------------------------------\n",
            "100 Loss:  719710.0009765625\n",
            "-----------------------------------\n",
            "200 Loss:  1426388.0146484375\n",
            "-----------------------------------\n",
            "300 Loss:  2118312.509765625\n",
            "-----------------------------------\n",
            "400 Loss:  2844602.0776367188\n",
            "-----------------------------------\n",
            "500 Loss:  3527796.35546875\n",
            "-----------------------------------\n",
            "600 Loss:  4236084.115722656\n",
            "-----------------------------------\n",
            "700 Loss:  4929082.58203125\n",
            "-----------------------------------\n",
            "800 Loss:  5627358.8076171875\n",
            "-----------------------------------\n",
            "900 Loss:  6317331.392578125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 2/20 [03:16<29:27, 98.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  6779.30029296875\n",
            "-----------------------------------\n",
            "100 Loss:  720322.3813476562\n",
            "-----------------------------------\n",
            "200 Loss:  1426955.2001953125\n",
            "-----------------------------------\n",
            "300 Loss:  2119108.8256835938\n",
            "-----------------------------------\n",
            "400 Loss:  2846040.9345703125\n",
            "-----------------------------------\n",
            "500 Loss:  3529748.0302734375\n",
            "-----------------------------------\n",
            "600 Loss:  4237668.589355469\n",
            "-----------------------------------\n",
            "700 Loss:  4931059.034667969\n",
            "-----------------------------------\n",
            "800 Loss:  5630630.357910156\n",
            "-----------------------------------\n",
            "900 Loss:  6320950.158203125\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 3/20 [04:54<27:48, 98.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  6774.27978515625\n",
            "-----------------------------------\n",
            "100 Loss:  719482.5458984375\n",
            "-----------------------------------\n",
            "200 Loss:  1426846.767578125\n",
            "-----------------------------------\n",
            "300 Loss:  2120233.2954101562\n",
            "-----------------------------------\n",
            "400 Loss:  2846580.455078125\n",
            "-----------------------------------\n",
            "500 Loss:  3529436.0180664062\n",
            "-----------------------------------\n",
            "600 Loss:  4238224.235839844\n",
            "-----------------------------------\n",
            "700 Loss:  4932300.986328125\n",
            "-----------------------------------\n",
            "800 Loss:  5631930.26171875\n",
            "-----------------------------------\n",
            "900 Loss:  6322257.02734375\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 4/20 [06:31<26:07, 97.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Loss:  6775.24951171875\n",
            "-----------------------------------\n",
            "100 Loss:  719541.4301757812\n",
            "-----------------------------------\n",
            "200 Loss:  1426227.3383789062\n",
            "-----------------------------------\n",
            "300 Loss:  2119280.0048828125\n",
            "-----------------------------------\n",
            "400 Loss:  2846194.3159179688\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-147da7c28438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoiseinputimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotionblurmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-207e4f03e1fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# x = F.relu(self.conv4(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# x = self.pool(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_conv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    840\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    841\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM9TX9AgoV-D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}